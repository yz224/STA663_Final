{
 "metadata": {
  "name": "",
  "signature": "sha256:3c61af816bc0e65e0cbbf5ef262472c81962a11d963fd2d7f7e6df19055919be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Paper Choice: Bayesian Hierachical Clustering\n",
      "###Yikun Zhou (yz224)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###1. background:  \n",
      "Hierarchical clustering is one of the most frequently used methods in unsupervised learning.But the traditional hierarchical clustering method provides no guide to choosing the \u201ccorrect\u201d number of clusters or the level at which to prune the tree. Also, The traditional algorithm does not define a probabilistic model of the data, so it is hard to ask how \u201cgood\u201d a clustering is. So, here we can use Bayesian Hierachical Clustering to overcome these limitations. \n",
      "\n",
      "####Problem that BHC can solve:\n",
      "\n",
      "a). bayesian model can give probability of test point belonging to any existing cluster  \n",
      "b). merging cluster based on model rather than ad-hoc matrics  \n",
      "c). use hypothesis test to give recommendation of merges  \n",
      "d). can be intepreted as approximation of dirichlet process  \n",
      "\n",
      "####Algorithm\n",
      "\n",
      "#####step1. \n",
      "input data $D=(x^1,x^2,...,x^n)$, define model  $p(x|\\theta)$, prior  $p(\\theta|\\beta)$\n",
      "\n",
      "#####step2.\n",
      "initialize number of clusters c = n  \n",
      "each cluster$D_i = (x^i)$ for $i=1,2,..n$\n",
      "\n",
      "#####step3.\n",
      "While c>1  \n",
      "find pair $D_i, D_j$with highest probability of merge:  \n",
      "  \n",
      "$r_k = \\dfrac{\\pi_k p(D_k|H_1^k)}{p(D_k|T_k)}$\n",
      "  \n",
      "Then Merge $D_i, D_j -> D_k$  \n",
      "$c <- c-1$\n",
      "\n",
      "#####loop"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}